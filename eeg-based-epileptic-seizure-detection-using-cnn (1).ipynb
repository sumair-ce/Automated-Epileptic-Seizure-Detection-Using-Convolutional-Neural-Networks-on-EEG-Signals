{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10173481,"sourceType":"datasetVersion","datasetId":6283490}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# Set random seed for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nprint(\"Libraries Imported Successfully\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-21T05:20:29.117459Z","iopub.execute_input":"2025-12-21T05:20:29.117787Z","iopub.status.idle":"2025-12-21T05:20:51.170224Z","shell.execute_reply.started":"2025-12-21T05:20:29.117766Z","shell.execute_reply":"2025-12-21T05:20:51.169121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the dataset\n# Note: Kaggle usually mounts datasets under /kaggle/input/\ntry:\n    # Attempt to locate the file automatically\n    import os\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(f\"Found file: {os.path.join(dirname, filename)}\")\n            if filename.endswith('.csv'):\n                file_path = os.path.join(dirname, filename)\n    \n    df = pd.read_csv(file_path)\n    print(f\"\\nDataset loaded. Shape: {df.shape}\")\n\nexcept Exception as e:\n    print(\"Could not automatically find path. Please verify the dataset is added.\")\n    # Fallback path (Update this if specific path differs)\n    # df = pd.read_csv('/kaggle/input/eeg-dataset/EEG_Scaled_data.csv') \n\n# Display first few rows\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T05:20:52.316619Z","iopub.execute_input":"2025-12-21T05:20:52.317481Z","iopub.status.idle":"2025-12-21T05:24:32.311770Z","shell.execute_reply.started":"2025-12-21T05:20:52.317457Z","shell.execute_reply":"2025-12-21T05:24:32.310695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Separate Features and Target\n# Assuming the target is the last column based on standard Kaggle datasets\nX = df.iloc[:, :-1].values\ny = df.iloc[:, -1].values\n\n# Check classes\nclasses = np.unique(y)\nprint(f\"Classes found: {classes}\")\n\n# Encode labels to 0 and 1 if they aren't already\nle = LabelEncoder()\ny = le.fit_transform(y)\n\n# --- PLOT FEATURES (Average Signal per Class) ---\n# This fulfills \"plot features as well\"\nplt.figure(figsize=(15, 6))\n\n# Plot average signal for Non-Epileptic\nclass_0_idx = np.where(y == 0)[0]\nplt.plot(X[class_0_idx].mean(axis=0), label='Non-Epileptic (Average)', color='blue', alpha=0.7)\n\n# Plot average signal for Epileptic\nclass_1_idx = np.where(y == 1)[0]\nplt.plot(X[class_1_idx].mean(axis=0), label='Epileptic (Average)', color='red', alpha=0.7)\n\nplt.title(\"Feature Plot: Average EEG Signal Amplitude by Class\")\nplt.xlabel(\"Time / Feature Index\")\nplt.ylabel(\"Signal Amplitude\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# NOTE ON TOPOGRAPHIC MAPS:\n# Topographic maps (Topoplots) require 3D spatial coordinates (e.g., Fp1, C3, Oz) for every column.\n# Since this dataset contains flattened data (36k+ columns) without explicit channel headers in the CSV,\n# we cannot generate an accurate topographic map. The plot above serves as the feature visualization.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T05:24:40.065915Z","iopub.execute_input":"2025-12-21T05:24:40.066410Z","iopub.status.idle":"2025-12-21T05:24:46.890125Z","shell.execute_reply.started":"2025-12-21T05:24:40.066374Z","shell.execute_reply":"2025-12-21T05:24:46.889095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (\n    Conv1D, \n    BatchNormalization, \n    MaxPooling1D, \n    GlobalAveragePooling1D, \n    Dense, \n    Dropout\n)\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# ------------------ DOWNSAMPLE & PCA ------------------\n# Reduce 36k+ features to ~1024 for faster training\npca = PCA(n_components=6000)\nX_reduced = pca.fit_transform(X)\n\n# Reshape for Conv1D: (samples, timesteps, 1)\nX_cnn = X_reduced.reshape(X_reduced.shape[0], X_reduced.shape[1], 1)\nprint(f\"Shape after PCA & reshape: {X_cnn.shape}\")\n\n# ------------------ TRAIN/TEST SPLIT ------------------\nX_train, X_test, y_train, y_test = train_test_split(\n    X_cnn, y, test_size=0.2, stratify=y, random_state=42\n)\n\n# Compute class weights for imbalance\nclass_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = dict(enumerate(class_weights))\nprint(f\"Class Weights: {class_weight_dict}\")\n\n# ------------------ BUILD CNN MODEL ------------------\ndef build_cnn(input_shape):\n    model = Sequential()\n    model.add(Conv1D(16, kernel_size=8, strides=2, activation='relu', input_shape=input_shape))\n    model.add(BatchNormalization())\n    model.add(MaxPooling1D(4))\n\n    model.add(Conv1D(32, kernel_size=4, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling1D(4))\n\n    model.add(GlobalAveragePooling1D())  # Faster than Flatten\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\nmodel = build_cnn(X_train.shape[1:])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T05:52:55.318765Z","iopub.execute_input":"2025-12-21T05:52:55.319104Z","iopub.status.idle":"2025-12-21T06:09:59.516800Z","shell.execute_reply.started":"2025-12-21T05:52:55.319083Z","shell.execute_reply":"2025-12-21T06:09:59.515283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------ TRAIN MODEL ------------------\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n\nhistory = model.fit(\n    X_train, y_train,\n    epochs=50,\n    batch_size=32, \n    validation_data=(X_test, y_test),\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T06:10:16.196483Z","iopub.execute_input":"2025-12-21T06:10:16.197816Z","iopub.status.idle":"2025-12-21T06:15:23.870878Z","shell.execute_reply.started":"2025-12-21T06:10:16.197777Z","shell.execute_reply":"2025-12-21T06:15:23.869757Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Training vs Validation Loss\nplt.figure(figsize=(14, 5))\n\n# Subplot 1: Loss\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss', color='blue')\nplt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\nplt.title('Model Loss (Check for Overfitting)')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\n\n# Subplot 2: Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)\nplt.savefig('training_history_plot.png', dpi=300)\nplt.show()\n\n# Textual check for overfitting\nval_loss = history.history['val_loss']\nif val_loss[-1] > min(val_loss) + 0.05:\n    print(\"\\nWARNING: Potential Overfitting detected (Validation loss increased).\")\nelse:\n    print(\"\\nModel training looks stable (Validation loss is low).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T06:45:38.399876Z","iopub.execute_input":"2025-12-21T06:45:38.400692Z","iopub.status.idle":"2025-12-21T06:45:39.138394Z","shell.execute_reply.started":"2025-12-21T06:45:38.400662Z","shell.execute_reply":"2025-12-21T06:45:39.137277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predictions\ny_pred_prob = model.predict(X_test)\ny_pred = (y_pred_prob > 0.5).astype(int)\n\n# Metrics\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"-\" * 30)\nprint(f\"Accuracy:  {acc:.4f}\")\nprint(f\"Precision: {prec:.4f}\")\nprint(f\"Recall:    {rec:.4f}\")\nprint(f\"F1 Score:  {f1:.4f}\")\nprint(\"-\" * 30)\n\n# Full Report\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(y_test, y_pred))\n\n# Confusion Matrix Plot\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Epileptic', 'Epileptic'], yticklabels=['Non-Epileptic', 'Epileptic'])\nplt.title('Confusion Matrix')\nplt.ylabel('Actual Label')\nplt.xlabel('Predicted Label')\nplt.savefig('confusion_matrix.png', dpi=300)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T06:46:38.425900Z","iopub.execute_input":"2025-12-21T06:46:38.427138Z","iopub.status.idle":"2025-12-21T06:46:40.015421Z","shell.execute_reply.started":"2025-12-21T06:46:38.427101Z","shell.execute_reply":"2025-12-21T06:46:40.013522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.signal import welch, spectrogram\n\n# --- CONFIGURATION ---\nfs = 173.61  # Sampling rate of CHB-MIT dataset is typically 256Hz or 173.61Hz. \n             # We will use 173.61Hz which is common for the processed version of this dataset.\n             # If unsure, standard medical EEG is often analyzed normalized, but this scaling works for visualization.\n\n# 1. Select One Sample from Each Class for Comparison\n# Find index of a seizure and non-seizure sample\nidx_seizure = np.where(y == 1)[0][0]      # First seizure sample\nidx_normal = np.where(y == 0)[0][0]       # First normal sample\n\n# Get the data (reshaping to 1D array for signal analysis)\nsig_seizure = X[idx_seizure]\nsig_normal = X[idx_normal]\n\n# --- PLOT 1: POWER SPECTRAL DENSITY (PSD) ---\n# This fulfills \"Band Frequencies\"\nf_seizure, psd_seizure = welch(sig_seizure, fs=fs, nperseg=1024)\nf_normal, psd_normal = welch(sig_normal, fs=fs, nperseg=1024)\n\nplt.figure(figsize=(12, 6))\nplt.semilogy(f_normal, psd_normal, label='Non-Epileptic (Normal)', color='blue', alpha=0.7)\nplt.semilogy(f_seizure, psd_seizure, label='Epileptic Seizure', color='red', alpha=0.7)\nplt.title('Power Spectral Density (PSD) Comparison')\nplt.xlabel('Frequency (Hz)')\nplt.ylabel('Power (Log Scale)')\nplt.legend()\nplt.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\nplt.xlim(0, 50)  # Focus on 0-50Hz range where brain waves happen\nplt.show()\n\n# --- PLOT 2: BRAIN BAND POWERS (Bar Chart) ---\n# This fulfills \"Band Powers\"\n# Define bands: Delta (0.5-4), Theta (4-8), Alpha (8-13), Beta (13-30), Gamma (30+)\nbands = {'Delta': (0.5, 4), 'Theta': (4, 8), 'Alpha': (8, 13), 'Beta': (13, 30), 'Gamma': (30, 50)}\n\ndef get_band_power(freqs, psd, band_range):\n    idx = np.logical_and(freqs >= band_range[0], freqs <= band_range[1])\n    return np.trapz(psd[idx], freqs[idx])\n\n# Calculate powers\npowers_seizure = [get_band_power(f_seizure, psd_seizure, band) for band in bands.values()]\npowers_normal = [get_band_power(f_normal, psd_normal, band) for band in bands.values()]\n\n# Plot Bar Chart\nx = np.arange(len(bands))\nwidth = 0.35\n\nplt.figure(figsize=(10, 6))\nplt.bar(x - width/2, powers_normal, width, label='Normal', color='blue', alpha=0.6)\nplt.bar(x + width/2, powers_seizure, width, label='Seizure', color='red', alpha=0.6)\nplt.xticks(x, bands.keys())\nplt.ylabel('Relative Power')\nplt.title('Brain Band Power Distribution (Energy per Frequency Band)')\nplt.legend()\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.savefig('Band_Power_Distribution.png', dpi=300)\nplt.show()\n\n# --- PLOT 3: SPECTROGRAM (Time-Frequency Map) ---\n# This is a great alternative to Topographic maps for single-channel/flattened data\nf, t, Sxx = spectrogram(sig_seizure, fs=fs, nperseg=256, noverlap=128)\n\nplt.figure(figsize=(12, 5))\nplt.pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud', cmap='inferno')\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [sec]')\nplt.title('Spectrogram of Epileptic Seizure (Time vs Frequency Intensity)')\nplt.colorbar(label='Intensity (dB)')\nplt.ylim(0, 50)  # Zoom in on relevant frequencies\nplt.savefig('Spectogram.png', dpi=300)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T06:48:28.433506Z","iopub.execute_input":"2025-12-21T06:48:28.435202Z","iopub.status.idle":"2025-12-21T06:48:31.398940Z","shell.execute_reply.started":"2025-12-21T06:48:28.435128Z","shell.execute_reply":"2025-12-21T06:48:31.397950Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# 1. Extract Accuracy Data\ntrain_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nepochs_range = range(1, len(train_acc) + 1)\n\n# 2. Create the Plot\nplt.figure(figsize=(10, 6))\n\n# Plot Training Accuracy\nplt.plot(epochs_range, train_acc, label='Training Accuracy', color='blue', linewidth=2, marker='o', markersize=4)\n\n# Plot Validation (Test) Accuracy\nplt.plot(epochs_range, val_acc, label='Validation (Test) Accuracy', color='orange', linewidth=2, marker='o', markersize=4)\n\n# 3. Add Labels and Title\nplt.title('Training vs Validation Accuracy', fontsize=16, fontweight='bold')\nplt.xlabel('Epochs', fontsize=12)\nplt.ylabel('Accuracy', fontsize=12)\nplt.legend(loc='lower right', fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.6)\n\n# 4. Save the Plot\n# saves to the /kaggle/working/ directory\nplt.savefig('train_vs_test_accuracy.png', dpi=300, bbox_inches='tight')\nprint(\"Plot saved as 'train_vs_test_accuracy.png'\")\n\n# 5. Show the Plot\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T06:49:12.929426Z","iopub.execute_input":"2025-12-21T06:49:12.929793Z","iopub.status.idle":"2025-12-21T06:49:13.458400Z","shell.execute_reply.started":"2025-12-21T06:49:12.929770Z","shell.execute_reply":"2025-12-21T06:49:13.457227Z"}},"outputs":[],"execution_count":null}]}